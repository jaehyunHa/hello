boxplot(cars)
boxplot(cars)
help(str)
help(datasets)
library(help = "datasets")
data("cars")
data(iris)
data(iris)
head(iris)
data("AirPassengers")
head(AirPassengers)
plot(ap, ylab="Passengers (1000s)", type="o", pch =20)
ap <- AirPassengers
plot(ap, ylab="Passengers (1000s)", type="o", pch =20)
ap.decompM <- decompose(ap, type = "multiplicative")
plot(ap.decompM)
head(car)
library(car)
head(cars)
(m <- lm(dist~speed, data=cars))
coef(m)
fitted(m)
residuals(m)
predict(m,newdata = data.frame(speed=5))
summary(m)
plot(cars$speed,residuals(m))
plot(m,which = 2)
full <- lm(dist~speed,data = cars)
reduced <- lm(dist~1,data=cars)
anova(reduced,full)
g
names(cars)
data(BostonHousing)
install.packages("mlbench")
data(BostonHousing)
data(BostonHousing)
library(mlbench)
data(BostonHousing)
m <- lm(medv~.,data=BostonHousing)
step(m, direction = "both")
step(m, direction = "backword")
step(m, direction = "forword")
names(BostonHousing)
step(m, direction = 'backword')
step(m, direction = 'backword')
step(m, direction = 'backward')
step(m, direction = 'forward')
#svc
x <- matrix(rnorm(20*2),ncol = 2)
y <- c(rep(-1,10),rep(1,10))
x[y==1,] <- x[y==1,] +1
plot(x,col=(3-y))
dat <- data.frame(x=x, y=as.factor(y))
library(e1071)
install.packages("e1071")
library(e1071)
m <- svm(y~., data=dat, kernel="linear", cost=10, scale = F)
plot(m,dat)
plot(m,dat)
4+5
7/2
10%2
10*3
x <- c(1,2,3,4)
x
summary(x)
xx <- scan()
xx
mean(xx)
median(xx)
var(xx)
setwd("C:/jaehyun_R")
install.packages(c("e1071", "foreign", "MASS", "mgcv", "survival"))
5<5
5==5
3<=2
x <- 3
y <- 2
x/y
xi <- 1+2i
xi
yi <- 1-2i
xi+yi
str <- "string"
str
"string"
TRUE
FALSE
T
F
xinf <- Inf
yinf <- Inf
yinf <- -Inf
xinf/yinf
sum(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
KK <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
ls()
seq(1,10)
seq(1,101)
seq(1,101, by=2)
seq(1,101, by=1)
seq(1,101, by=3)
seq(1,100, by=2, from =2)
library(KoNLP)
library("KoNLP")
setwd("~/")
library("KoNLP")
library(KoNLP)
seq(1,100, by=2, length.out=20)
seq(1,100,length.out=20)
seq(1,100,length.out=20)
seq(1,100,length.out=10)
rep(c(1,2,3), times=3))
rep(c(1,2,3), times=3)
rep(1:4, 2)
library(KoNLP)
install.packages("KoNLP")
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
library(KoNLP)
install.packages(“KoNLP”)
install.packages("KoNLP")
library(KoNLP)
install.packages("KoNLP")
library(KoNLP)
sessionInfo()
install.packages("KoNLP")
library(KoNLP)
install.packages("KoNLP")
remove.packages("KoNLP", lib="~/R/win-library/3.5")
install.packages("KoNLP", lib="C:/Program Files/R/R-3.5.1/library")
library(KoNLP)
.libPaths()
library(KoNLP)
install.packages("KoNLP", lib="C:/Program Files/R/R-3.5.1/library")
detach("package:KoNLP", unload = TRUE)
library(KoNLP)
detach("package:KoNLP", unload = TRUE)
install.packages("KoNLP", lib="C:/Program Files/R/R-3.5.1/library")
library(KoNLP)
.libPaths()
library(recommenderlab)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(matrixStats)
install.packages("matrixStats")
library(matrixStats)
rating_df <- tribble(
~ user, ~슈퍼맨,  ~배트맨,  ~색계, ~아멜리에,
"병곤",     1 ,      2 ,      8 ,     10,
"용섭",     10,       7,       8,      3,
"우상",     8 ,      9 ,      9 ,     2,
"성수",     4 ,      5 ,      9 ,     7)
rating_mat <- rating_df %>%
remove_rownames() %>%
column_to_rownames(var="user") %>%
as.matrix()
rating_mat
DT::datatable(rating_mat)
library(recommenderlab)
library(tidyverse)
library(matrixStats)
DT::datatable(rating_mat)
install.packages("DT")
library(DT)
DT::datatable(rating_mat)
(rating_svd <- svd(rating_mat))
D <- diag(rating_svd$d)
D[3:4, 3:4] <- 0
(rating_approx <- rating_svd$u %*% D %*% t(rating_svd$v))
sum(rating_mat - rating_approx)
rating_mat[2,c(2,4)] <- 0
rating_mean <- rowMeans(rating_mat)
rating_std  <- rowSds(rating_mat)
rating_mat[2,c(2,4)] <- rating_mean[2] * 2
rating_std_mat <- apply(rating_mat, 1, scale)
(rating_std_svd <- svd(rating_std_mat))
D <- diag(rating_std_svd$d)
D[3:4, 3:4] <- 0
rating_std_mf <- rating_std_svd$u %*% D %*% t(rating_std_svd$v)
rating_mean + rating_std_mf * rating_std
f3= function(x){1/9*x^2}
(p3<-integrate(f3, lower=1, upper=2))
7/27
f=function(x){0.5*x*x}
(m=integrate(f, lower=0, upper=2))
f2=function(x){0.5*x^3}
(v=integrate(f2, lower=0, upper=2))
x<-c(-1, 0, 1)
p<-c(1/4, 1/2, 1/4)
sum(x*p)
mean(x*p)
sum(x^2*p)-E_x^2
(E_x<-sum(x*p))
(V_x<-sum(x^2*p)-E_x^2)
var(x*p)
var(x^2*p)
sum(x^2*p)
E_x^2
(V_x<-sum(x^2*p)-E_x^2)
f3= function(x){1/9*x^2}
(p3<-integrate(f3, lower=1, upper=2))
7/27
#3)P(1<X<2)
f3= function(x){1/9*x^2}
(p3<-integrate(f3, lower=1, upper=2))
#p150
#9.
#평균
f=function(x){0.5*x*x}
(m=integrate(f, lower=0, upper=2))
#분산
f2=function(x){0.5*x^3}
(v=integrate(f2, lower=0, upper=2))
#10.
#1)확률그래프
x<-c(-1, 0, 1)
p<-c(1/4, 1/2, 1/4)
plot(x, p, type="h", lwd=5, col="blue")
#2)평균과 분산
(E_x<-sum(x*p))
(V_x<-sum(x^2*p)-E_x^2)
# 평균 취업률
# 전체취업률 mu = 54.5
stat <- scan()
shapiro.test(stat)  #귀무가설: 정규분포를 따른다
# 평균 취업률
# 전체취업률 mu = 54.5
stat <- scan()
# 정규성검정
shapiro.test(stat)  #귀무가설: 정규분포를 따른다
# 가설검정
t.test(stat,mu=54.5)
t.test(stat,mu=54.5,alternative="greater")  #대립가설: 54.5보다 크다
# Wilcoxon 부호순위검정(정규분포 안 따를때)
wilcox.test(stat,mu=54.5,alternative="greater")
### 표본크기결정(평균)
SizeMeanCI <- function(Error, Sigma, Conf.level=0.95)
{
alpha <- (1-Conf.level)/2
(Sigma*qnorm(1-alpha)/Error)^2
}
SizeMeanCI(1.5,5,0.95)
SizeMeanTest <- function(Effect,Sigma,Alpha=0.05,Power=0.8)
{
(Sigma*(qnorm(1-Alpha/2)+qnorm(Power))/Effect)^2
}
SizeMeanTest(5,10)
### 분산
# 제품강도
x <- scan()
# 수정제곱합
css <- sum((x-mean(x))^2)  # css <- (length(x)-1)*var(x)
# 자유도
df <- length(x)-1
# 분산신뢰구간
(Sigma2CI <- c(css/qchisq(0.975,df),css/qchisq(0.025,df)))
# 표준편차신뢰구간
sqrt(Sigma2CI)
### 비율추론
# Saxony 출생기록
n <- 73380
x <- 38100 #남아
p <- x/n
# 신뢰구간
prop.test(x,n)
# 가설검정
prop.test(x,n,p=0.5,alternative="greater")
### 표본크기결정(비율)
SizePropCI <- function(Error, Conf.level=0.95)
{
alpha <- (1-Conf.level)/2
(qnorm(1-alpha)/Error)^2/4
}
SizePropCI(0.031,0.95)
SizePropTest <- function(prop1,prop2,Alpha=0.05,Power=0.8)
{
delta = prop2-prop1
term <- qnorm(1-Alpha/2)*sqrt(prop1*(1-prop1))+qnorm(Power)*sqrt(prop2*(1-prop2))
(term/delta)^2
}
SizePropTest(0.4,0.5)
gc()
setwd("C:/범죄예측2장")
cyber_bullying=read.table(file='cyber_bullying_sam.txt', header = T) ##
attach(cyber_bullying)
cyber_bullying1=data.frame(Strain, Physical, Psychological, Self_control, Attachment,
Passion, Perpetrator, Delinquency)
summary(lm(Delinquency~.,data = cyber_bullying1))  #모든 독립변수에 대해 1차 다중회귀분석
#2차 다중회귀분석
#유의한 독립변수에 대해 다중회귀분석 실시
sel=lm(Delinquency~Strain+Physical+Self_control+Attachment+Perpetrator, data=cyber_bullying1)
anova(sel)   #회귀계수 검정(요인에 대한 분산분석)
#3차
summary(lm(Delinquency~Strain+Physical+Self_control+Perpetrator, data=cyber_bullying1))
#표준화 회귀계수 산출
library(lm.beta)
lm1=lm(Delinquency~Strain+Physical+Self_control+Perpetrator, data=cyber_bullying1)
#유의한 변수만 다중회귀분석 실시
lm.beta(lm1)
sel=lm(Delinquency~Strain+Physical+Self_control+Perpetrator, data=cyber_bullying1)
anova(sel)
#잔차의 정규성 검정
shapiro.test(residuals(sel))
#잔차의 자기상관 검정
library(lmtest)
dwtest(set)  #더빈-왓슨 검정
dwtest(sel)  #더빈-왓슨 검정
#회귀모형의 잔차는 상호독립이라는 귀무가설 기각되어 잔차 간의 자기상관 있는 것으로 나타남
confint(sel)  #회귀계수에 대한 95% 신뢰구간 분석
#모형의 비교
fit_s=lm(Delinquency~Strain)
fit_t=lm(Delinquency~Strain+Physical+Self_control+Perpetrator, data=cyber_bullying1)
anova(fit_s, fit_t)
#2. 단계적 투입방법에 의한 다중회귀분석
library(MASS)
sel=lm(Delinquency~., data=cyber_bullying1)
setp_set=step(sel, direction = 'both')   #변수선택법: both, backward, forward
summary(setp_sel)
summary(setp_set)
#ex)8개의 GST 요인에 포함된 변수에 대한 신뢰성을 측정하라
library(psych)
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_reliability.txt', header = T) ##
attach(cyber_bullying)
cyber_bullying1=cbind(Strain, Physical, Psychological, Self_control, Attachment,
Passion, Perpetrator, Delinquency)
cyber_bullying=read.table(file='cyber_bullying_reliability.txt', header = T) ##
attach(cyber_bullying)
factor1=cbind(Strain, Physical, Psychological, Self_control, Attachment,
Passion, Perpetrator, Delinquency)
alpha(factor1)
#2차 신뢰성 분석
factor1=cbind(Strain, Physical, Psychological, Attachment,
Passion, Perpetrator, Delinquency)
alpha(factor1)
cyber_bullying=read.table(file='cyber_bullying_descriptive_analysis.txt', header = T)
attach(cyber_bullying)
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_descriptive_analysis.txt', header = T)
attach(cyber_bullying)
tapply(Onespread, Channel, mean)
tapply(Onespread, Channel, sd)
tapply(Onespread, Account, mean)
tapply(Onespread, Account, sd)
tapply(Onespread, list(Channel,Account), mean)
tapply(Onespread, list(Channel,Account), sd)
#채널별 순계정별 1주 확산수의 평균과 표준편차
tapply(Twospread, Channel, mean)
tapply(Twospread, Channel, sd)
tapply(Twospread, Account, mean)
tapply(Twospread, Account, sd)
tapply(Twospread, list(Channel,Account), mean)
tapply(Twospread, list(Channel,Account), sd)
Mfit=manova(y~Account, Channel, Account:Channel)
Mfit
Mfit=manova(y~Account, Channel, Account:Channel)  #이원 다변량 분산분석
#다변량 분산분석
y=cbind(Onespread, Twospread)
Mfit=manova(y~Account+Channel+ Account:Channel)  #이원 다변량 분산분석
Mfit
summary(Mfit, test='Wilks')
summary(Mfit, test='Pillai')
summary(Mfit, test='Roy')
summary(Mfit, test='Hotelling')
summary.aov(Mfit)
#ex)사이버 학교폭력 감정(attitude(negative/positive))에 영향 미치는 GST요인은 무엇인가?
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_methodology_numeric.txt', header = T)
attach(cyber_bullying)
#ex)사이버 학교폭력 감정(attitude(negative/positive))에 영향 미치는 GST요인은 무엇인가?
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_methodology_numeric.txt', header = T)
input=read.table('input_binary_logistic.txt', header = T, sep=',')
input=read.table(file='input_binary_logistic.txt', header = T, sep=',')
input=read.table(file='input_binary_logistic.txt', header = T, sep=",")
input=read.table('input_binary_logistic.txt', header = T, sep=",")
View(input)
output=read.table('out_binary_logistic.txt', header = T, sep=",")
output=read.table('output_binary_logistic.txt', header = T, sep=",")
attach(cyber_bullying)
input_vars=c(colnames(input))
output_vars=c(colnames(output))
form=as.formula(paste(paste(output_vars,collapse = '+'),'~',paste(input_vars, collapse = '+')))
form
summary(glm(form, family = binomial, data = cyberbullying))
summary(glm(form, family = binomial, data = cyber_bullying))
exp(coef(glm(form, family = binomial, data = cyber_bullying)))
exp(confint(glm(form, family = binomial, data = cyber_bullying)))
#이분형 로지스틱 회귀모형의 결정계수 산출
model=glm(form, family = binomial, data = cyber_bullying)
pR2(model)
#이분형 로지스틱 회귀모형의 결정계수 산출
library(pscl)
pR2(model)
#19)다항 로지스틱 회귀분석
#독립변수들이 양적 변수를 가지며 종속변수가 3개 이상의 범주 갖는 회귀모형
library(nnet)
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_multinomial_logistic.txt', header = T)
input=read.table('input_binary_logistic.txt', header = T, sep=",")
output=read.table('output_binary_logistic.txt', header = T, sep=",")
attach(cyber_bullying)
input_vars=c(colnames(input))
output_vars=c(colnames(output))
form=as.formula(paste(paste(output_vars,collapse = '+'),'~',paste(input_vars, collapse = '+')))
form
model=multinom(form, data = cyber_bullying)
summary(model)
model=multinom(form, data = cyber_bullying)
summary(model)
output=read.table('output_multinomial_logistic', header = T, sep=",")
output_vars=c(colnames(output))
form=as.formula(paste(paste(output_vars,collapse = '+'),'~',paste(input_vars, collapse = '+')))
form
model=multinom(form, data = cyber_bullying)
summary(model)
rm(list=ls())
cyber_bullying=read.table(file='cyber_bullying_multinomial_logistic.txt', header = T)
input=read.table('input_binary_logistic.txt', header = T, sep=",")
output=read.table('output_multinomial_logistic', header = T, sep=",")
output=read.table('output_multinomial_logistic.txt', header = T, sep=",")
attach(cyber_bullying)
input_vars=c(colnames(input))
output_vars=c(colnames(output))
form=as.formula(paste(paste(output_vars,collapse = '+'),'~',paste(input_vars, collapse = '+')))
form
model=multinom(form, data = cyber_bullying)
summary(model)
z=summary(model)$coefficents/summary(model)$standard.errors
#multinom 함수는 p-value를 산출할 수 없으므로 z-test(wald tests) 사용해 p-value 산출
p=(1-pnorm(abs(z),0,1))*2   #p-value
p
exp(coef(model))
exp(confint(model))
z=summary(model)$coefficients/summary(model)$standard.errors
#multinom 함수는 p-value를 산출할 수 없으므로 z-test(wald tests) 사용해 p-value 산출
p=(1-pnorm(abs(z),0,1))*2   #p-value
p
exp(coef(model))
exp(confint(model))
